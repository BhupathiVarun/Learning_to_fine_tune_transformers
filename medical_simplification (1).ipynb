{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d475145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 03:15:12.208031: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 03:15:12.219710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744753512.233693   25489 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744753512.238122   25489 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744753512.251040   25489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744753512.251063   25489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744753512.251065   25489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744753512.251066   25489 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-16 03:15:12.254982: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/geetheswar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM,\n",
    "    T5ForConditionalGeneration,\n",
    "    BartForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d050517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cbasu/Med-EASi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea61465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
       "        num_rows: 1397\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
       "        num_rows: 196\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Expert', 'Simple', 'Annotation', 'sim', 'sentence_sim', 'compression', 'expert_fk_grade', 'expert_ari', 'layman_fk_grade', 'layman_ari', 'umls_expert', 'umls_layman', 'expert_terms', 'layman_terms', 'idx'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c81f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n",
      "Train set: 1397 examples\n",
      "Validation set: 196 examples\n",
      "Test set: 300 examples\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    print(\"Preprocessing dataset...\")\n",
    "    # Convert dataset to pandas DataFrame for easier manipulation\n",
    "    train_df = pd.DataFrame(dataset['train'])\n",
    "    test_df = pd.DataFrame(dataset['test'])\n",
    "    val_df = pd.DataFrame(dataset['validation'])\n",
    "    \n",
    "    print(f\"Train set: {len(train_df)} examples\")\n",
    "    print(f\"Validation set: {len(val_df)} examples\")\n",
    "    print(f\"Test set: {len(test_df)} examples\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d46569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_for_model(train_df, val_df, test_df, tokenizer, max_input_length=256, max_target_length=256):\n",
    "    # Process individual examples directly\n",
    "    train_encodings = []\n",
    "    val_encodings = []\n",
    "    test_encodings = []\n",
    "    \n",
    "    # Process training data\n",
    "    for _, row in train_df.iterrows():\n",
    "        model_inputs = tokenizer(\n",
    "            row[\"Expert\"], \n",
    "            max_length=max_input_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                row[\"Simple\"],\n",
    "                max_length=max_target_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        train_encodings.append(model_inputs)\n",
    "    \n",
    "    # Process validation data\n",
    "    for _, row in val_df.iterrows():\n",
    "        model_inputs = tokenizer(\n",
    "            row[\"Expert\"], \n",
    "            max_length=max_input_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                row[\"Simple\"],\n",
    "                max_length=max_target_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        val_encodings.append(model_inputs)\n",
    "    \n",
    "    # Process test data\n",
    "    for _, row in test_df.iterrows():\n",
    "        model_inputs = tokenizer(\n",
    "            row[\"Expert\"], \n",
    "            max_length=max_input_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                row[\"Simple\"],\n",
    "                max_length=max_target_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        test_encodings.append(model_inputs)\n",
    "    \n",
    "    # Convert to PyTorch datasets with simplified __getitem__\n",
    "    class TextSimplificationDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings):\n",
    "            self.encodings = encodings\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            # Simply return the pre-processed encodings\n",
    "            return self.encodings[idx]\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.encodings)\n",
    "    \n",
    "    train_dataset = TextSimplificationDataset(train_encodings)\n",
    "    val_dataset = TextSimplificationDataset(val_encodings)\n",
    "    test_dataset = TextSimplificationDataset(test_encodings)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f63a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, tokenizer):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Clip predictions to valid token range to prevent overflow errors\n",
    "    # Get tokenizer vocabulary size\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    \n",
    "    # Clip predictions to be within valid token range\n",
    "    predictions = np.clip(predictions, 0, vocab_size - 1)\n",
    "    \n",
    "    try:\n",
    "        # Decode generated summaries and reference texts\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        # Rouge expects newline after each sentence\n",
    "        decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "        decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "        \n",
    "        # Compute ROUGE scores\n",
    "        rouge_metric = evaluate.load(\"rouge\")\n",
    "        result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "        \n",
    "        # Extract ROUGE f1 scores\n",
    "        result = {k: round(v * 100, 2) for k, v in result.items()}\n",
    "        \n",
    "        # Compute BLEU score\n",
    "        bleu_metric = evaluate.load(\"bleu\")\n",
    "        bleu_result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result[\"bleu\"] = round(bleu_result[\"bleu\"] * 100, 2)\n",
    "        \n",
    "        # Compute readability metrics\n",
    "        result[\"fk_grade_diff\"] = calculate_readability_improvement(decoded_preds, decoded_labels)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_metrics: {e}\")\n",
    "        # Return default metrics in case of failure\n",
    "        result = {\n",
    "            \"rouge1\": 0.0,\n",
    "            \"rouge2\": 0.0,\n",
    "            \"rougeL\": 0.0,\n",
    "            \"bleu\": 0.0,\n",
    "            \"fk_grade_diff\": 0.0\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Calculate readability improvement using Flesch-Kincaid Grade Level\n",
    "def calculate_readability_improvement(simplified_texts, original_texts):\n",
    "    def flesch_kincaid_grade(text):\n",
    "        # Simple implementation of Flesch-Kincaid Grade Level\n",
    "        sentences = sent_tokenize(text)\n",
    "        num_sentences = len(sentences)\n",
    "        if num_sentences == 0:\n",
    "            return 0\n",
    "            \n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        num_words = len(words)\n",
    "        if num_words == 0:\n",
    "            return 0\n",
    "            \n",
    "        syllables = 0\n",
    "        for word in words:\n",
    "            syllables += count_syllables(word)\n",
    "            \n",
    "        fk_grade = 0.39 * (num_words / num_sentences) + 11.8 * (syllables / num_words) - 15.59\n",
    "        return max(0, fk_grade)  # Grade level should not be negative\n",
    "    \n",
    "    # Calculate the average grade level difference\n",
    "    grade_diffs = []\n",
    "    for original, simplified in zip(original_texts, simplified_texts):\n",
    "        original_grade = flesch_kincaid_grade(original)\n",
    "        simplified_grade = flesch_kincaid_grade(simplified)\n",
    "        grade_diff = original_grade - simplified_grade  # Positive value means simplified text is easier to read\n",
    "        grade_diffs.append(grade_diff)\n",
    "    \n",
    "    return sum(grade_diffs) / len(grade_diffs) if grade_diffs else 0\n",
    "\n",
    "# Syllable counting helper function\n",
    "def count_syllables(word):\n",
    "    # Simple syllable counting - this is a basic implementation\n",
    "    word = word.lower()\n",
    "    if len(word) <= 3:\n",
    "        return 1\n",
    "    \n",
    "    # Remove ending e\n",
    "    if word.endswith('e'):\n",
    "        word = word[:-1]\n",
    "        \n",
    "    # Count vowel groups\n",
    "    vowels = \"aeiouy\"\n",
    "    count = 0\n",
    "    prev_is_vowel = False\n",
    "    \n",
    "    for char in word:\n",
    "        is_vowel = char in vowels\n",
    "        if is_vowel and not prev_is_vowel:\n",
    "            count += 1\n",
    "        prev_is_vowel = is_vowel\n",
    "        \n",
    "    return max(1, count)  # Every word has at least one syllable\n",
    "\n",
    "# Fine-tune model\n",
    "def fine_tune_model(model_name, tokenizer, train_dataset, val_dataset, output_dir):\n",
    "    print(f\"Fine-tuning {model_name}...\")\n",
    "    \n",
    "    # Load pre-trained model and tokenizer\n",
    "    if \"t5\" in model_name.lower():\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    elif \"bart\" in model_name.lower():\n",
    "        model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "    else:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    # Set up the data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=3,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=512,\n",
    "        report_to=\"none\",  # Disable wandb reporting\n",
    "        save_strategy=\"epoch\",\n",
    "    )\n",
    "    \n",
    "    # Create Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics= lambda p: compute_metrics(p, tokenizer),\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save best model\n",
    "    trainer.save_model(output_dir)\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc38ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geetheswar/.miniconda3/envs/datasci/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model1_name)\n",
    "train_dataset, val_dataset, test_dataset = prepare_dataset_for_model(train_df, val_df, test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f040ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning google/flan-t5-small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geetheswar/.miniconda3/envs/datasci/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_25149/239469128.py:142: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 05:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Fk Grade Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.625526</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.689968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.900900</td>\n",
       "      <td>0.552572</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.224760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.628100</td>\n",
       "      <td>0.464969</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>-66.285841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbed5a93e6774d5196955012ccae8666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaca5f61e3264b31a8b72009bb6a5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf43c70292540eea9c7138fdd697cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flan_t5_model, flan_t5_trainer = fine_tune_model(model1_name, tokenizer, train_dataset, val_dataset, \"flan_t5_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a25456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geetheswar/.miniconda3/envs/datasci/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning facebook/bart-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geetheswar/.miniconda3/envs/datasci/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_25489/239469128.py:142: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 08:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Fk Grade Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337914</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>13.290000</td>\n",
       "      <td>23.340000</td>\n",
       "      <td>23.970000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>4.996868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.072300</td>\n",
       "      <td>0.329956</td>\n",
       "      <td>32.030000</td>\n",
       "      <td>17.280000</td>\n",
       "      <td>28.440000</td>\n",
       "      <td>28.920000</td>\n",
       "      <td>11.010000</td>\n",
       "      <td>4.114712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.331769</td>\n",
       "      <td>33.360000</td>\n",
       "      <td>18.530000</td>\n",
       "      <td>29.490000</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>14.220000</td>\n",
       "      <td>3.291828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geetheswar/.miniconda3/envs/datasci/lib/python3.11/site-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model2_name = \"facebook/bart-base\"\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model2_name)\n",
    " \n",
    "train_dataset2, val_dataset2, test_dataset2 = prepare_dataset_for_model(\n",
    "    train_df, val_df, test_df, tokenizer2\n",
    ")\n",
    "\n",
    "model2, trainer2 = fine_tune_model(\n",
    "    model2_name, tokenizer2, train_dataset2, val_dataset2, \"./results_bart\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc68a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataset, model_name, tokenizer):\n",
    "    print(f\"Testing {model_name}...\")\n",
    "    \n",
    "    # Set up the data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True,\n",
    "    )\n",
    "    \n",
    "    # Define test arguments\n",
    "    test_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=f\"./test_results_{model_name}\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=512,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    # Create Trainer for evaluation\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=test_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p, tokenizer),\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test dataset\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069483a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing bart...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25489/3320418237.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results2 = test_model(model2, test_dataset2, \"bart\", tokenizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39e99752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27668920159339905,\n",
       " 'eval_model_preparation_time': 0.0016,\n",
       " 'eval_rouge1': 32.35,\n",
       " 'eval_rouge2': 18.08,\n",
       " 'eval_rougeL': 28.72,\n",
       " 'eval_rougeLsum': 29.35,\n",
       " 'eval_bleu': 15.45,\n",
       " 'eval_fk_grade_diff': 2.3486921533359393,\n",
       " 'eval_runtime': 54.1928,\n",
       " 'eval_samples_per_second': 5.536,\n",
       " 'eval_steps_per_second': 1.384}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a55852",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1710c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(model, tokenizer, expert_text):\n",
    "    inputs = tokenizer(expert_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs)\n",
    "    \n",
    "    simplified_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return simplified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6b9ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The patient was diagnosed with pneumonia, requiring immediate hospitalization and intravenous antibiotics.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_text = \"The patient was diagnosed with a severe case of pneumonia, requiring immediate hospitalization and intravenous antibiotics.\"\n",
    "simplified_text = simplify(bart, tokenizer2, expert_text)\n",
    "simplified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ad0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes, the drug desmopressin\n"
     ]
    }
   ],
   "source": [
    "expert_text = \"Desmopressin\"\n",
    "simplified_text = simplify(bart, tokenizer2, expert_text)\n",
    "simplified_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9fd16",
   "metadata": {},
   "source": [
    "## Problems\n",
    "- Due to small input context length, the text is masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47e0e907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people have weight loss, rarely enough to become underweight. Anemia, glossitis'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_text = \"Some patients have weight loss, rarely enough to become underweight. Anemia, glossitis, angular stomatitis, and aphthous ulcers are usually seen in these patients.\"\n",
    "simplified_text = simplify(bart, tokenizer2, expert_text)\n",
    "simplified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ed2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
